## 운영체제
<!--
  <details>
    <summary></summary>
  </details>
-->

<details>
  <summary><h3>1. 시스템 콜이 무엇인지 설명해 주세요.</h3></summary>
  시스템 콜은 운영체제의 서비스를 프로그램이 요청할 때 사용하는 인터페이스입니다. 사용자 모드에서 실행되는 프로그램이 운영체제의 커널 모드 서비스를 사용하려면, 이를 위한 정해진 절차를 따라야 하는데 그것이 바로 시스템 콜입니다.

---
  <details>
    <summary>우리가 사용하는 시스템 콜의 예시를 들어주세요. </summary>
    흔히 사용하는 시스템 콜로는 파일을 열거나 닫는 'open', 'close', 프로세스를 생성하거나 종료하는 'fork', 'exit', 메모리를 할당하거나 해제하는 'malloc', 'free' 등이 있습니다
  </details>  
  <details>
    <summary>시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요. </summary>
    프로그램이 시스템 콜을 호출하면, 우선 프로그램의 실행 상태는 사용자 모드에서 커널 모드로 전환됩니다. 그리고 시스템 콜 번호와 인자를 통해 어떤 서비스를 요청하는지를 운영체제에 알립니다. 운영체제는 이 정보를 바탕으로 해당 작업을 수행한 후, 결과를 프로그램에 반환하고 다시 사용자 모드로 전환합니다.
  </details>  
  <details>
    <summary>시스템 콜의 유형에 대해 설명해 주세요.</summary>
    시스템 콜은 크게 프로세스 관리, 파일 관리, 장치 관리, 정보 관리, 통신 등의 유형으로 나뉠 수 있습니다.
  </details>  
    <details>
    <summary>운영체제의 Dual Mode 에 대해 설명해 주세요.</summary>
      운영체제의 Dual Mode는 사용자 모드와 커널 모드로 구분되어 있습니다. 사용자 모드에서는 제한된 권한으로 실행되며, 시스템 자원에 직접 접근할 수 없습니다. 반면 커널 모드에서는 모든 시스템 자원에 접근 가능하며, 운영체제의 모든 기능을 사용할 수 있습니다.
  </details> 
  <details>
    <summary>왜 유저모드와 커널모드를 구분해야 하나요? </summary>
    이 구분은 시스템의 안정성과 보안을 위해 필요합니다. 사용자 프로그램이 잘못된 동작을 하더라도 시스템 전체에 영향을 치지 않도록 하기 위해서입니다. 또한, 프로그램이 운영체제의 서비스를 사용할 때는 반드시 시스템 콜을 통해야 하므로, 이를 통해 운영체제는 프로그램의 요청을 검토하고 제어할 수 있습니다. 
  </details>  
    <details>
    <summary>서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?</summary>
      시스템 콜은 각각 고유의 번호를 가지고 있습니다. 프로그램이 시스템 콜을 호출할 때, 이 번호를 통해 어떤 시스템 콜을 호출하는지를 운영체제에 알립니다. 그래서 운영체제는 이 번호를 통해 시스템 콜을 구분하고, 해당하는 서비스를 제공하게 됩니다.
  </details>  
</details>

<details>
  <summary><h3>2. 인터럽트가 무엇인지 설명해 주세요.</h3></summary>
  인터럽트는 CPU에게 어떤 사건이 발생했음을 알리는 신호입니다. 이는 외부 장치, 운영체제, 또는 실행 중인 프로그램으로부터 발생할 수 있습니다. 인터럽트가 발생하면 CPU는 현재 처리 중인 작업을 중단하고 인터럽트를 처리하게 됩니다. 

  ---
  
  <details>
    <summary>인터럽트는 어떻게 처리하나요?</summary>
    인터럽트가 발생하면 우선 현재 CPU의 상태를 저장합니다. 그러고 나서 인터럽트를 발생시킨 원인을 파악하고, 해당 인터럽트를 처리하는 루틴을 실행합니다. 처리가 끝나면 이전에 중단된 작업으로 돌아가게 됩니다
  </details>  
  <details>
    <summary>Polling 방식에 대해 설명해 주세요.</summary>
    Polling 방식은 CPU가 주기적으로 장치를 확인하여 데이터의 준비 상태를 확인하는 방식입니다. 데이터가 준비되었을 때 CPU는 그 데이터를 가져와 처리하게 됩니다. 이 방식은 간단하지만, CPU의 시간을 많이 소모할 수 있습니다.
  </details>  
  <details>
    <summary>HW / SW 인터럽트에 대해 설명해 주세요.</summary>
     HW 인터럽트는 외부 장치로부터 발생하는 인터럽트를 말합니다. 예를 들어 키보드 키 입력, 마우스 클릭 등이 이에 해당합니다. 반면 SW 인터럽트는 프로그램의 실행 중에 발생하는 인터럽트를 말하며, 시스템 콜 호출, 오류 발생 등이 이에 해당합니다. 
  </details>  
  <details>
    <summary>동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?</summary>
    여러 인터럽트가 동시에 발생한 경우, 각 인터럽트는 우선순위를 가지고 있습니다. 우선순위가 높은 인터럽트부터 처리하게 됩니다. 만약 우선순위가 같은 인터럽트가 동시에 발생하면, 먼저 발생한 인터럽트를 먼저 처리하게 됩니다.
  </details>
</details>

<details>
  <summary><h3>3. 프로세스가 무엇인가요?</h3></summary>
   프로세스는 운영체제에서 프로그램이 메모리에 로드되어 실행되는 상태를 말합니다. 프로세스는 각각 독립된 메모리 공간을 할당받아 사용하며, 이를 통해 다른 프로세스가 자신의 메모리 공간에 접근하는 것을 방지합니다. 프로세스는 운영체제의 스케줄링에 의해 CPU를 할당받아 실행되며, 필요에 따라 시스템 자원을 요청하거나 사용합니다.

   ---

  <details>
    <summary>프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.</summary>
    프로그램은 디스크 상에 저장된 실행 코드입니다. 프로세스는 프로그램이 실행되어 실제로 메모리 상에 올라간 상태를 말하며, 스레드는 프로세스 내에서 실행 흐름의 단위입니다. 즉, 프로세스는 실행 중인 프로그램이고, 스레드는 프로세스 내에서 실제로 작업을 수행하는 단위입니다.
  </details> 
  <details>
    <summary>PCB(Process Control Block)가 무엇인가요?</summary>
    PCB는 운영체제가 프로세스를 관리하기 위해 사용하는 데이터 구조입니다. 프로세스의 상태, 프로세스 ID, 프로그램 카운터, CPU 레지스터 값, 메모리 관리 정보 등 프로세스에 대한 중요한 정보를 포함하고 있습니다.
  </details> 
    <details>
    <summary>그렇다면, 스레드는 PCB를 갖고 있을까요?</summary>
      스레드는 프로세스 내에서 독립적으로 실행되는 실행 흐름이지만, 동일한 프로세스 내의 스레드들은 메모리와 자원을 공유합니다. 따라서 스레드는 별도의 PCB를 가지지 않고, 프로세스의 PCB를 공유하게 됩니다. 그러나 스레드마다 독립적인 스택과 레지스터 값, 프로그램 카운터 등을 가집니다. 
  </details> 
    <details>
    <summary>리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?</summary>
      리눅스에서 프로세스는 'fork' 시스템 콜을 사용해 생성됩니다. 'fork'는 현재 프로세스를 복제하여 새로운 프로세스를 생성합니다. 스레드는 'pthread_create' 함수를 사용해 생성됩니다. 이 함수는 동일한 프로세스 내에서 새로운 실행 흐름을 생성합니다. 
  </details> 
    <details>
    <summary>자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?</summary>
      자식 프로세스가 상태를 알리지 않고 종료하거나, 부모 프로세스가 먼저 종료되는 경우, 이는 '좀비 프로세스' 또는 '고아 프로세스'가 됩니다. 운영체제는 이러한 상황을 처리하기 위해 'init' 프로세스를 사용합니다. 'init' 프로세스는 고아 프로세스를 자식 프로세스로 받아들이고, 좀비 프로세스의 상태를 수집하여 시스템 자원을 회수합니다.
  </details> 
    <details>
    <summary>리눅스에서, 데몬프로세스에 대해 설명해 주세요.</summary>
      데몬 프로세스는 백그라운드에서 실행되는 프로세스입니다. 사용자와 직접적으로 상호작용하지 않고, 시스템 관리나 서버 프로세스 등을 위해 주로 사용됩니다.
  </details> 
    <details>
    <summary>리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.</summary>
      리눅스에서 프로세스가 형성하는 트리 구조의 루트 노드는 'init' 프로세스입니다. 'init' 프로세스는 시스템 부팅 시 생성되며, 모든 다른 프로세스의 부모 프로세스가 됩니다. 따라서 'init' 프로세스는 시스템이 종료될 때까지 계속 실행됩니다.
  </details> 
</details>

<details>
  <summary><h3>4. 프로세스 주소공간에 대해 설명해 주세요.</h3></summary>
   프로세스 주소 공간은 프로세스가 실행되기 위해 필요한 코드, 데이터, 힙, 스택 등을 저장하는 메모리 공간입니다. 이 공간은 각 프로세스마다 독립적으로 존재하며, 각 영역은 다음과 같은 정보를 담고 있습니다.

  - 코드 영역: 프로그램의 명령어가 저장되는 영역
- 데이터 영역: 전역 변수와 정적 변수가 저장되는 영역
- 힙 영역: 동적 할당을 통해 생성된 변수나 객체가 저장되는 영역
- 스택 영역: 함수의 호출 정보와 지역 변수가 저장되는 영역

---
  
  <details>
    <summary>초기화 하지 않은 변수들은 어디에 저장될까요?</summary>
    초기화하지 않은 전역 변수와 정적 변수는 데이터 영역의 BSS(Block Started by Symbol) 영역에 저장됩니다.
  </details> 
  <details>
    <summary>일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?</summary>
    스택과 힙 영역의 크기는 고정적이지 않고, 프로그램의 실행 과정에서 동적으로 변합니다. 스택 영역은 함수 호출이 일어날 때마다 증가하고 함수가 종료되면 감소하며, 힙 영역은 동적 메모리 할당을 통해 크기가 변합니다.
  </details> 
  <details>
    <summary>Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?</summary>
    스택 영역이 힙 영역보다 접근 속도가 빠릅니다. 이는 스택이 LIFO(후입선출; Last In First Out) 원칙에 따라 데이터를 저장하고 접근하기 때문입니다.
  </details> 
  <details>
    <summary>다음과 같이 공간을 분할하는 이유가 있을까요?</summary>
     주소 공간을 분할함으로써 각 영역의 역할에 따라 메모리를 효율적으로 관리할 수 있습니다. 예를 들어, 스택과 힙 영역을 분리함으로써 동적 메모리 할당과 함수 호출을 독립적으로 관리할 수 있습니다. 
  </details> 
  <details>
    <summary>스레드의 주소공간은 어떻게 구성되어 있을까요?</summary>
    스레드는 프로세스 내에서 실행되므로 프로세스의 주소 공간을 공유합니다. 그러나 각 스레드는 독립적인 스택 영역을 가집니다.
  </details> 
  <details>
    <summary>"스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.</summary>
    "스택" 영역은 자료구조의 스택과 같이 LIFO(후입선출) 원칙에 따라 동작하며, "힙" 영역은 메모리를 동적으로 할당하고 해제하는 영역입니다. 자료구조의 힙과는 다르게 구조적인 특성은 없습니다. 
  </details> 
  <details>
    <summary>IPC(Inter-Process Communication)의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?</summary>
    IPC의 Shared Memory 기법은 프로세스 간 데이터를 공유하기 위해 사용되며, 이는 힙 영역에 할당됩니다. 이는 힙 영역이 동적으로 메모리를 할당하고 해제할 수 있기 때문입니다. 
  </details>  
  <details>
    <summary>스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요?</summary>
    스택과 힙 영역의 초기 크기는 운영체제에서 결정되며, 실행 중에 동적으로 변합니다. 일반적으로 프로그램 개발자는 이 크기를 직접 수정할 수 없습니다. 그러나 운영체제의 설정을 통해 스택의 최대 크기 등을 조정할 수 있습니다.
  </details>  
</details>

<details>
  <summary><h3>5. 단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.</h3></summary>
<ul>
<li> 현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?</li>
<li> 프로세스의 스케쥴링 상태에 대해 설명해 주세요.</li>
<li> preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?</li>
<li> Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?</li>
</ul>
</details>

<details>
  <summary><h3>6. 컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?</h3></summary>
<ul>
<li> 프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?</li>
<li> 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?</li>
<li> 컨텍스트 스위칭은 언제 일어날까요?</li>
</ul>
</details>

<details>
  <summary><h3>7. 프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?</h3></summary>
<ul>
<li> RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.</li>
<li> 싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?</li>
<li> 동시성과 병렬성의 차이에 대해 설명해 주세요.</li>
<li> 타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?</li>
<li> FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요? </li>
<li> 우리는 스케줄링 알고리즘을 "프로세스" 스케줄링 알고리즘이라고 부릅니다. 스레드는 다른 방식으로 스케줄링을 하나요?</li>
<li> 유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?</li>
</ul>
</details>

<details>
  <summary><h3>8. 뮤텍스와 세마포어의 차이점은 무엇인가요?</h3></summary>
<ul>
<li> 이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.</li>
<li> Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?</li> 
<li> 뮤텍스와 세마포어 모두 커널이 관리하기 때문에, Lock을 얻고 방출하는 과정에서 시스템 콜을 호출해야 합니다. 이 방법의 장단점이 있을까요? 단점을 해결할 수 있는 방법은 없을까요?</li>
</ul>
</details>

<details>
  <summary><h3>9. Deadlock 에 대해 설명해 주세요.</h3></summary>
<ul>
<li> Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.</li>
<li> 그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?</li>
<li> 어떤 방식으로 예방할 수 있을까요?</li>
<li> 왜 현대 OS는 Deadlock을 처리하지 않을까요?</li>
<li> Wait Free와 Lock Free를 비교해 주세요.</li>
</ul>
</details>

<details>
  <summary><h3>10. 프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.</h3></summary>
<ul>
<li> 링커와, 로더의 차이에 대해 설명해 주세요.</li>
<li> 컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.</li>
<li> JIT에 대해 설명해 주세요.</li>
<li> 본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요.</li>
<li> Python 같은 언어는 CPython, Jython, PyPy등의 다양한 구현체가 있습니다. 각각은 어떤 차이가 있을까요? 또한, 실행되는 과정 또한 다를까요?</li>
<li> 우리는 흔히 fork(), exec() 시스템 콜을 사용하여 프로세스를 적재할 수 있다고 배웠습니다. 로더의 역할은 이 시스템 콜과 상관있는 걸까요? 아니면 다른 방식으로 프로세스를 적재할 수 있는 건가요?</li>
</ul>
</details>

<details>
  <summary><h3>11. IPC가 무엇이고, 어떤 종류가 있는지 설명해 주세요.</h3></summary>
<ul>
<li> Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.</li>
<li> 메시지 큐는 단방향이라고 할 수 있나요?</li>
</ul>
</details>

<details>
  <summary><h3>12. Thread Safe 하다는 것은 어떤 의미인가요?</h3></summary>
<ul>
<li> Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?</li>
<li> Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.</li>
<li> Race Condition 이 무엇인가요?</li>
<li> Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?</li>
</ul>
</details>

<details>
  <summary><h3>13. Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.</h3></summary>
<ul>
<li> Thread Pool을 사용한다고 가정하면, 어떤 기준으로 스레드의 수를 결정할 것인가요? </li>
<li> 어떤 데이터를 정렬 하려고 합니다. 어떤 방식의 전략을 사용하는 것이 가장 안전하면서도 좋은 성능을 낼 수 있을까요?</li>
</ul>
</details>

<details>
  <summary><h3>14. 캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.</h3></summary>
<ul>
<li> 캐시 메모리는 어디에 위치해 있나요?</li>
<li> L1, L2 캐시에 대해 설명해 주세요.</li>
<li> 캐시에 올라오는 데이터는 어떻게 관리되나요?</li>
<li> 캐시간의 동기화는 어떻게 이루어지나요?</li>
<li> 캐시 메모리의 Mapping 방식에 대해 설명해 주세요.</li>
<li> 캐시의 지역성에 대해 설명해 주세요.</li>
<li> 캐시의 지역성을 기반으로, 이차원 배열을 가로/세로로 탐색했을 때의 성능 차이에 대해 설명해 주세요.</li>
<li> 캐시의 공간 지역성은 어떻게 구현될 수 있을까요? (힌트: 캐시는 어떤 단위로 저장되고 관리될까요?) </li>
</ul>
</details>

<details>
  <summary><h3>15.메모리의 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)</h3></summary>
<ul>
<li> worst-fit 은 언제 사용할 수 있을까요?</li>
<li> 성능이 가장 좋은 알고리즘은 무엇일까요?</li>
</ul>
</details>

<details>
  <summary><h3>16. Thrashing 이란 무엇인가요?</h3></summary>
<ul>
<li> Thrashing 발생 시, 어떻게 완화할 수 있을까요?</li>
</ul>
</details>

<details>
  <summary><h3>17. 가상 메모리란 무엇인가요?</h3></summary>
<ul>
<li> 가상 메모리가 가능한 이유가 무엇일까요?</li>
<li> Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.</li>
<li> 페이지 크기에 대한 Trade-Off를 설명해 주세요.</li>
<li> 페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?</li>
<li> 세그멘테이션 방식을 사용하고 있다면, 가상 메모리를 사용할 수 없을까요?</li>

</ul>
</details>

<details>
  <summary><h3>18. 세그멘테이션과 페이징의 차이점은 무엇인가요?</h3></summary>
<ul>
<li> 페이지와 프레임의 차이에 대해 설명해 주세요.</li>
<li> 내부 단편화와, 외부 단편화에 대해 설명해 주세요.</li>
<li> 페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.</li>
<li> 어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?</li>
<li> 32비트에서, 페이지의 크기가 1kb 이라면 페이지 테이블의 최대 크기는 몇 개일까요?</li>
<li> 32비트 운영체제는 램을 최대 4G 까지 사용할 수 있습니다. 이 이유를 페이징과 연관 지어서 설명해 주세요.</li>
<li> C/C++ 개발을 하게 되면 Segmentation Fault 라는 에러를 접할 수 있을텐데, 이 에러는 세그멘테이션/페이징과 어떤 관계가 있을까요? </li> 
</ul>
</details>

<details>
  <summary><h3>19. TLB는 무엇인가요?</h3></summary>
<ul>
<li> TLB를 쓰면 왜 빨라지나요?</li>
<li> MMU가 무엇인가요?</li>
<li> TLB와 MMU는 어디에 위치해 있나요?</li>
<li> 코어가 여러개라면, TLB는 어떻게 동기화 할 수 있을까요? </li>
<li> TLB 관점에서, Context Switching 발생 시 어떤 변화가 발생하는지 설명해 주세요. </li>
</ul>
</details>

<details>
  <summary><h3>20. 동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.</h3></summary>
<ul>
<li> volatile 키워드는 어떤 의미가 있나요?</li>
<li> 싱글코어가 아니라 멀티코어라면, 어떻게 동기화가 이뤄질까요?</li>
<li> 
</ul>
</details>

<details>
  <summary><h3>21. 페이지 교체 알고리즘에 대해 설명해 주세요.</h3></summary>
<ul>
<li> LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요?</li>
<li> LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?</li>
<li> LRU 알고리즘의 단점을 설명해 주세요. 이를 해결할 수 있는 대안에 대해서도 설명해 주세요.</li>
</ul>
</details>

<details>
  <summary><h3>22. File Descriptor와, File System에 에 대해 설명해 주세요.</h3></summary>
<ul>
<li> I-Node가 무엇인가요?</li>
<li> 프로그래밍 언어 상에서 제공하는 파일 관련 함수 (Python - open(), Java - BufferedReader/Writer 등)은, 파일을 어떤 방식으로 읽어들이나요?</li>
</ul>
</details>

<details>
  <summary><h3>23. 동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.</h3></summary>
<ul>
<li> 그렇다면, 동기이면서 논블로킹이고, 비동기이면서 블로킹인 경우는 의미가 있다고 할 수 있나요?</li>
<li> I/O 멀티플렉싱에 대해 설명해 주세요.</li>
<li> 논블로킹 I/O를 수행한다고 하면, 그 결과를 어떻게 수신할 수 있나요? </li>
</ul>
</details>
